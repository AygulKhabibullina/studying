{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "4_Neural_Style_Transfer_with_Eager_Execution.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "nbTranslate": {
      "displayLangs": [
        "ru"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "ru",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo5PziEC4hWs"
      },
      "source": [
        "# Neural Style Transfer with tf.keras\n",
        "\n",
        "Оригинальный ноутбук можно скачать по ссылкам:\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/models/blob/master/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/models/blob/master/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "MuqaaDwdw0S5"
      },
      "source": [
        "## Обзор\n",
        "\n",
        "В этом уроке мы узнаем, как использовать глубокое обучение для создания изображений в стиле образца (вам когда-нибудь хотелось, чтобы вы рисовали, как Пикассо или Ван Гог?). Этот метод известен как **нейронная передача стиля**. Этот метод, описан в [статье Леона А. Гатиса «Нейронный алгоритм художественного стиля» (https://arxiv.org/abs/1508.06576), статья очень полезная, и вы обязательно должны ее посмотреть.\n",
        "\n",
        "Что такое нейронная передача стиля?\n",
        "\n",
        "Нейронная передача стиля - это метод оптимизации, используемый для трех изображений: изображения **содержания**, изображения **эталонного стиля** (например, работы известного художника) и **входного** изображения. Нужно смешать их таким образом, чтобы входное изображение выглядело как изображение содержания, но было «нарисовано» в эталонном стиле.\n",
        "\n",
        "\n",
        "Давайте возьмем изображение этой черепахи и *Великой волны у Канагавы* Кацушика Хокусая:\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/models/blob/master/research/nst_blogpost/Green_Sea_Turtle_grazing_seagrass.jpg?raw=1\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
        "<img src=\"https://github.com/tensorflow/models/blob/master/research/nst_blogpost/The_Great_Wave_off_Kanagawa.jpg?raw=1\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
        "\n",
        "[Изображение Зеленой Морской Черепахи] (https://commons.wikimedia.org/wiki/File:Green _Морская_ Черепаха _пасется_ seagrass.jpg)\n",
        "- П. Линдгрен [CC BY-SA 3.0 (https://creativecommons.org/licenses/by-sa/3.0)], из общего собрания Викимедиа\n",
        "\n",
        "\n",
        "Как бы это выглядело, если бы Хокусай решил нарисовать картину этой Черепахи таким стилем? Что-то вроде этого?\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/models/blob/master/research/nst_blogpost/wave_turtle.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
        "\n",
        "Это какая-то магия или всего лишь глубокое обучение? К счастью, это не колдовство: передача стиля - забавная и интересная техника, которая демонстрирует возможности нейронных сетей.\n",
        "\n",
        "Принцип нейронной передачи стиля заключается в определении двух разных функций, одна из которых описывает, насколько различается содержимое двух изображений, $L_{content}$, а другая описывает разницу между стилями двух изображений, $L_{style}$. Далее, имея три изображения, желаемое изображение стиля, желаемое изображение содержания и входное изображение, мы пытаемся преобразовать входное изображение так, чтобы минимизировать его отличияот изображения содержания и отличия от изображения эталонного стиля. Мы преобразуем базовое входное изображение, сводя к минимуму расстояния (потери) содержимого и стиля с помощью метода обратного распространения.\n",
        "\n",
        "### Понятия, рассматриваемые в статье:\n",
        "В процессе мы будем накапливать практический опыт и развивать интуицию в следующих концепциях:\n",
        "\n",
        "* Моментальное исполнение (Eager Execution) - использовать императивную среду программирования TensorFlow, которая выполняет операции незамедлительно\n",
        "    * [Узнайте больше о Eager Execution](https://www.tensorflow.org/programmers _guide / eager)  \n",
        "    * [Посмотреть его в действии](https://www.tensorflow.org/get_ запущен / готов)\n",
        "* Использование [Functional API](https://keras.io/getting-started/functional-api-guide/) для определения модели* *- мы создадим подмножество моделей, которое даст нам доступ к необходимым промежуточным функциям активации с помощью Functional API* \n",
        "* Использование карт признаков (feature map) предварительно обученной модели* - Узнайте, как использовать предварительно обученнные модели и их карты признаков\n",
        "* Создание обучающих циклов*- мы рассмотрим, как настроить оптимизатор для минимизации заданных потерь входных параметрам\n",
        "\n",
        "### Мы должны выполнить следующие шаги для передачи стиля:\n",
        "\n",
        "1. Визуализация данных\n",
        "2. Базовая первичная обработка и подготовка данных\n",
        "3. Настройка функции потерь\n",
        "4. Создание модели\n",
        "5. Оптимизация функции потери \n",
        "\n",
        "**Аудитория:** Этот пост предназначен для пользователей среднего уровня, которые знакомы с базовыми концепциями машинного обучения. Чтобы получить максимальную пользу от этого поста, вам следует:\n",
        "* Прочитать [статью Гатиса](https://arxiv.org/abs/1508.06576) - статья предоставит более глубокое понимание задачи\n",
        "* [Понять уменьшение потерь с помощью градиентного спуска](https://developers.google.com/machine-learning/crash-course/reduc-loss/gradient-descent)\n",
        "\n",
        "**Расчетное время**: 30 минут"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2uSMsQABNnB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8ajP_u73s6m"
      },
      "source": [
        "## Первоначальная настройка\n",
        "\n",
        "### Загрузить изображения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T09:31:51.222008Z",
          "start_time": "2019-07-16T09:31:21.150700Z"
        },
        "id": "riWE_b8k3s6o"
      },
      "source": [
        "import os\n",
        "img_dir = '/tmp/nst'\n",
        "if not os.path.exists(img_dir):\n",
        "    os.makedirs(img_dir)\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/d/d7/Green_Sea_Turtle_grazing_seagrass.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/0/0a/The_Great_Wave_off_Kanagawa.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/b/b4/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/6/68/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://i.ibb.co/WHmm58q/photo-2021-12-15-16-26-22.jpg\n",
        "!wget --quiet -P /tmp/nst/  https://i.ibb.co/xHJwY4L/photo-2021-12-15-17-09-04.jpg\n",
        "!wget --quiet -P /tmp/nst/ https://klike.net/uploads/posts/2019-05/1556707966_3.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqxUicSPUOP6"
      },
      "source": [
        "Импорт модулей и настройка конфигурации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T09:34:09.274437Z",
          "start_time": "2019-07-16T09:34:08.993079Z"
        },
        "id": "sc1OLbOWhPCO"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (10,10)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import time\n",
        "import functools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T09:34:21.438322Z",
          "start_time": "2019-07-16T09:34:12.480609Z"
        },
        "id": "RYEjlrYk3s6w"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.keras.preprocessing import image as kp_image\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "Ru0QT2brw0TD"
      },
      "source": [
        "Мы начнем с добавления моментального исполнения [(eager execution)](https://www.tensorflow.org/guide/eager). Это позволит нам работать с этой техникой наиболее удобным способом."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T11:05:01.809406Z",
          "start_time": "2019-07-16T11:05:01.805674Z"
        },
        "id": "sfjsSAtNrqQx"
      },
      "source": [
        "#enable_eager_execution - выполняет операции сразу\n",
        "# executing_eagerly - проверяет включен ли eager execution\n",
        "tf.enable_eager_execution()\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T11:05:02.271937Z",
          "start_time": "2019-07-16T11:05:02.267195Z"
        },
        "id": "IOiGrIV1iERH"
      },
      "source": [
        "# Переменные для изобржения содержания и изображения стиля\n",
        "content_path = '/tmp/nst/Green_Sea_Turtle_grazing_seagrass.jpg'\n",
        "style_path = '/tmp/nst/The_Great_Wave_off_Kanagawa.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE4Yt8nArTeR"
      },
      "source": [
        "**Визуализация изображения**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T11:05:03.071216Z",
          "start_time": "2019-07-16T11:05:03.060064Z"
        },
        "id": "3TLljcwv5qZs"
      },
      "source": [
        "def load_img(path_to_img):\n",
        "    max_dim = 512\n",
        "    img = Image.open(path_to_img)\n",
        "    long = max(img.size)\n",
        "    scale = max_dim/long\n",
        "\n",
        "#img.size[0] и img.size[1] - ширина и высота\n",
        "    img = img.resize(\n",
        "        (round(img.size[0]*scale), round(img.size[1]*scale)), Image.ANTIALIAS)\n",
        "#img_to_array - конвертирует изображение PIL в массив Numpy\n",
        "    img = kp_image.img_to_array(img)\n",
        "\n",
        "    # We need to broadcast the image array such that it has a batch dimension\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T11:05:03.613128Z",
          "start_time": "2019-07-16T11:05:03.606386Z"
        },
        "id": "vupl0CI18aAG"
      },
      "source": [
        "def imshow(img, title=None):\n",
        "#  Функция squeeze() удаляет оси с одним элементом (длинной 1), но не сами элементы массива\n",
        "    # Remove the batch dimension\n",
        "    out = np.squeeze(img, axis=0)\n",
        "    # Нормализация отображения\n",
        "    out = out.astype('uint8')\n",
        "#imshow - отображение данных в виде изображения\n",
        "    plt.imshow(out)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.imshow(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "trVYqG8_w0TN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T11:05:06.210377Z",
          "start_time": "2019-07-16T11:05:05.221757Z"
        },
        "id": "_UWQmeEaiKkP"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "content = load_img(content_path).astype('uint8')\n",
        "style = load_img(style_path).astype('uint8')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "imshow(content, 'Изображение содержания')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "imshow(style, 'Изображение стиля')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "dUWtGmltw0TQ"
      },
      "source": [
        "## Подготовка данных\n",
        "Создадим методы, которые позволят нам легко загружать и обрабатывать изображения. Мы выполняем такой же процесс предварительной обработки, который предполагается процессом обучения VGG. Сети VGG обучаются на изображении с каждым каналом, нормализованным по `mean = [103.939, 116.779, 123.68]` и с каналами BGR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T11:09:38.715565Z",
          "start_time": "2019-07-16T11:09:38.452962Z"
        },
        "id": "hGwmTwJNmv2a"
      },
      "source": [
        "def load_and_process_img(path_to_img):\n",
        "    img = load_img(path_to_img)\n",
        "#tf.keras.applications.vgg19.preprocess_input() - предварительно обрабатывает tensor или массив Numpy\n",
        "    img = tf.keras.applications.vgg19.preprocess_input(img)\n",
        "    \n",
        "    return img\n",
        "\n",
        "ggg = load_and_process_img(content_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "RUXkvkV9w0TT"
      },
      "source": [
        "Чтобы просмотреть результаты нашей оптимизации, мы должны выполнить шаг обратной предварительной обработки. Кроме того, поскольку наше оптимизированное изображение может принимать значения в промежутке между $- \\infty$ и $\\infty$, мы должны сократить наши значения до значений в диапазоне 0-255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T11:10:05.300665Z",
          "start_time": "2019-07-16T11:10:05.275094Z"
        },
        "id": "mjzlKRQRs_y2"
      },
      "source": [
        "def deprocess_img(processed_img):\n",
        "    x = processed_img.copy()\n",
        "    if len(x.shape) == 4:\n",
        "        x = np.squeeze(x, 0)\n",
        "    assert len(x.shape) == 3, (\"Input to deprocess image must be an image of \"\n",
        "                               \"dimension [1, height, width, channel] or [height, width, channel]\")\n",
        "    if len(x.shape) != 3:\n",
        "        raise ValueError(\"Invalid input to deprocessing image\")\n",
        "\n",
        "    # выполнить инверсию шага предварительной обработки\n",
        "#     print(x)\n",
        "    x[:, :, 0] += 103.939\n",
        "#     print(x)\n",
        "    x[:, :, 1] += 116.779\n",
        "#     print(x)\n",
        "    x[:, :, 2] += 123.68\n",
        "#     print(x)\n",
        "    x = x[:, :, ::-1] # конвертиировать bgr в rgb\n",
        "\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "k = deprocess_img(ggg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "Y8OBhtp3w0TW"
      },
      "source": [
        "### Определение содержания и стиля изображения\n",
        "Чтобы получить представление о содержании и стиле изображения, мы рассмотрим некоторые промежуточные слои в нашей модели. По мере того, как мы углубляемся в модель, эти промежуточные слои, представляющие собой признаки, становтся более упорядоченными. В этом случае мы используем архитектуру VGG19, которая представляет собой предварительно обученную сеть для классификациии изображений. Промежуточные слои необходимы для определения содержимого и стиля изображений. Для входного изображения мы попытаемся сопоставить соответствующий стиль и содержание на этих промежуточных слоях.\n",
        "\n",
        "#### Почему промежуточные слои?\n",
        "\n",
        "Вы можете быть удивлены, почему эти промежуточные слои в предобученной сети классификации изображений позволяют определить стиль и содержание изображения. Это явление может быть объяснено тем фактом, что для того, чтобы сеть выполняла классификацию изображений (чему сеть уже была обучена), она должна понимать изображение. Это включает в себя использование необработанного изображения в виде входных пикселей и построение представления посредством преобразований, которые превращают необработанные пиксели изображения в сложные объекты, присутствующие в изображении. Это также частично объясняет, почему сверточные нейронные сети способны хорошо обобщать: они способны фиксировать постоянство и определять особеннности, характерные, какому либо классу (например, кошки и собаки), не зависящие от фонового шума. Таким образом, где-то между тем, где подается необработанное изображение и выводится результат классификации, модель служит в качестве экстрактора сложных признаков. Следовательно, получая доступ к промежуточным слоям, мы можем описать содержание и стиль входных изображений.\n",
        "\n",
        "\n",
        "В частности, мы извлечем эти промежуточные слои из нашей сети:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T11:14:38.346749Z",
          "start_time": "2019-07-16T11:14:38.341169Z"
        },
        "id": "N4-8eUp_Kc-j"
      },
      "source": [
        "# Слой содержания, в который помещается карта объектов\n",
        "content_layers = ['block5_conv2']\n",
        "\n",
        "# Интересный нам слой стиля\n",
        "style_layers = ['block1_conv1',\n",
        "                'block2_conv1',\n",
        "                'block3_conv1',\n",
        "                'block4_conv1',\n",
        "                'block5_conv1'\n",
        "                ]\n",
        "\n",
        "num_content_layers = len(content_layers)\n",
        "num_style_layers = len(style_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "t6aelYCDw0TY"
      },
      "source": [
        "## Построение модели\n",
        "Мы должны загрузить [VGG19] (https://keras.io/applications/#vgg19) и ввести входной тензор в модель. Это позволит нам получить карты признаков (и далее содержание и стиль) изображения.\n",
        "\n",
        "Мы используем VGG19, как предлагается в статье. Кроме того, поскольку VGG19 является относительно простой моделью (по сравнению с ResNet, Inception и т. Д.), карты признаков работают лучше для передачи стилей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "Bzd3Qv0ow0TZ"
      },
      "source": [
        "Чтобы получить доступ к промежуточным слоям, соответствующим картам признаков стиля и содержимого, мы должны получить соответствующие выходные данные,используя Keras [**functional API**](https://keras.io/getting-started/ function-api-guide /), мы определяем нашу модель с желаемыми выходными функциями активациями.\n",
        "\n",
        "С помощью functional API определение модели сводится к определению входных и выходных данных:\n",
        "\n",
        "`модель = модель (входы, выходы)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T13:07:04.294968Z",
          "start_time": "2019-07-16T13:07:04.284679Z"
        },
        "id": "nfec6MuMAbPx"
      },
      "source": [
        "def get_model():\n",
        "    \"\"\" Создание модели с доступом к промежуточным слоям.\n",
        "  \n",
        "    Эта функция будет загружать модель VGG19 и давать доступ к промежуточным слоям.\n",
        "    В дальнейшем эти слои будут использоваться для создания модели, которая будет брать входное изображение\n",
        "    и возвращать выходные данные с промежуточных слоёв модели VGG.\n",
        "    \"\"\"\n",
        "    # Загрузка нашей модели. Мы загружаем предобученную модель VGG\n",
        "    vgg = tf.keras.applications.vgg19.VGG19(\n",
        "        include_top=False, weights='imagenet')\n",
        "    vgg.trainable = False\n",
        "    # Получение слоев стиля и содержания\n",
        "    style_outputs = [vgg.get_layer(name).output for name in style_layers]\n",
        "    content_outputs = [vgg.get_layer(name).output for name in content_layers]\n",
        "    model_outputs = style_outputs + content_outputs\n",
        "    # Построение модели\n",
        "    return models.Model(vgg.input, model_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "Z25YFqODw0Tc"
      },
      "source": [
        "В приведенном выше фрагменте кода мы загрузим предварительно подготовленную сеть классификации изображений. Затем мы возьмем необходимые слои, как мы говорили ранее. Затем мы определяем модель, устанавливая входные данные для изображения, и выходные данные для выходных слоев стиля и содержимого. Другими словами, мы создали модель, которая будет брать входное изображение и выводить промежуточные слои содержимого и стиля."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "d4f7cPECw0Tf"
      },
      "source": [
        "## Определение и создание функции потерь (расстояний содержания и стиля)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "pEIMdPlKw0Th"
      },
      "source": [
        "### Функция потерь содержания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "gCuDI12Hw0Ti"
      },
      "source": [
        "Наше определение функции потери содержания довольно простое. Мы передадим сети желаемое изображение содержания и наше базовое входное изображение. После мы получим выходные данные промежуточного слоя из нашей модели. Затем мы просто берем евклидово расстояние между двумя промежуточными представлениями этих изображений.\n",
        "\n",
        "Более формально, функция потери содержимого - это функция, которая описывает расстояние содержимого от входного изображения $x$ и изображения содержимого $p$. Пусть $C_{nn}$ будет предварительно обученной глубокой сверточной нейронной сетью. Опять же, в этом случае мы используем [VGG19] (https://keras.io/applications/#vgg19). Пусть $X$ будет любым изображением, тогда $C_{nn}(X)$ - это сеть, на вход которой подается X. Пусть $F^l_{ij}(x) \\in C_{nn}(x)$ и $P^l_{ij}(p) \\in C_{nn}(p)$ описывают соответствующее промежуточное представление функции сети, принимающей на вход $x$ и $p$ на уровне $l$. Затем мы рассчитываем расстояние содержимого (потери) как: $$L^l_{content}(p, x) = \\sum_{i, j} (F^l_{ij}(x) - P^l_{ij}(p))^2$$\n",
        "\n",
        "Мы выполняем обратное распространение, чтобы минимизировать потерю содержимого. Таким образом, мы изменяем исходное изображение до тех пор, пока оно не сгенерирует ответ в определенном слое (определенный в content_layer) как исходное изображение контента.\n",
        "\n",
        "Это можно реализовать довольно просто. На вход нужно подать карту признаков слоя L в сети, со входом x, входное изображение, и p, изображение контента, и вернуть расстояние содержания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "RNPKOsEuw0Tk"
      },
      "source": [
        "### Вычисление функции потери содержания\n",
        "Мы добавим функцию потери содержания на каждом желаемом слое. Таким образом, при каждой итерации передачи входного изображение в модель, все потери содержимого в модели будут правильно вычисляться, и, поскольку мы используем моментальное исолнение, все градиенты будут вычислены."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2mf7JwRMkCd"
      },
      "source": [
        "def get_content_loss(base_content, target):\n",
        "    return tf.reduce_mean(tf.square(base_content - target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "Im17-Ckbw0Tr"
      },
      "source": [
        "## Функция потерь стиля"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "ZHFPy0S8w0Tz"
      },
      "source": [
        "Вычисление потери стиля немного сложнее, но базируется на том же принципу, но на этот раз в нашу сеть подается базовое входное изображение и изображение стиля. Однако вместо сравнения необработанных промежуточных выходных данных основного входного изображения и изображения стиля мы сравниваем матрицы Грамма двух выходных данных.\n",
        "\n",
        "Математически мы описываем потерю стиля основного входного изображения, $x$, и изображения стиля, $a$, как расстояние между представлением стиля (матрица Грама) этих изображений. Мы описываем представление стиля изображения как корреляцию между различными ответами фильтра, заданными матрицей Грама $G^l$, где $G^l_{ij}$ является внутренним произведением между векторизованной картой признаков $i$ и $j$ в слое $l$.\n",
        "\n",
        "Чтобы сгенерировать стиль для основного входного изображения, мы выполняем градиентный спуск от изображения содержимого для чтобы преобразовать его в изображение, соответствующее стилевому представлению исходного изображения. Мы делаем это путем минимизации среднего квадрата расстояния между картой корреляции изображения стиля и входного изображения. Вклад каждого слоя в общую потерю стиля описывается\n",
        "$$E_l = \\frac{1}{4N_l^2M_l^2} \\sum_{i,j}(G^l_{ij} - A^l_{ij})^2$$\n",
        "\n",
        "где $G^l_{ij}$ и $A^l_{ij}$ - соответствующее представление стиля в слое $l$ из $x$ и $a$. $N_l$ описывает количество карт объектов, каждая из которых имеет размер $M_l = height * width$. Таким образом, общая потеря стиля на каждом слое составляет\n",
        "$$L_{style}(a, x) = \\sum_{l \\in L} w_l E_l$$\n",
        "где взвешивается влияние потери каждого слоя на некоторый коэффициент $w_l$. В нашем случае мы взвешиваем каждый слой одинаково ($w_l =\\frac{1}{|L|}$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "sbcZjkwAw0T0"
      },
      "source": [
        "### Вычисление функции потерь стиля"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T13:02:45.445263Z",
          "start_time": "2019-07-16T13:02:45.426632Z"
        },
        "id": "N7MOqwKLLke8"
      },
      "source": [
        "def gram_matrix(input_tensor):\n",
        "    # Сначала идёт канал изображения\n",
        "    channels = int(input_tensor.shape[-1])\n",
        "    print(input_tensor.shape)\n",
        "    a = tf.reshape(input_tensor, [-1, channels])\n",
        "    print(a.shape)\n",
        "    n = tf.shape(a)[0]\n",
        "    gram = tf.matmul(a, a, transpose_a=True)\n",
        "    return gram / tf.cast(n, tf.float32)\n",
        "\n",
        "\n",
        "def get_style_loss(base_style, gram_target):\n",
        "    \"\"\"Принимает два изображения измерений h, w, c\"\"\"\n",
        "    # Высота, ширина и количество фильтров в каждом слое\n",
        "    # Масштабируем потерю в данном слое\n",
        "    height, width, channels = base_style.get_shape().as_list()\n",
        "    gram_style = gram_matrix(base_style)\n",
        "\n",
        "    # / (4. * (channels ** 2) * (width * height) ** 2)\n",
        "    return tf.reduce_mean(tf.square(gram_style - gram_target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "eBoZSBMRw0T5"
      },
      "source": [
        "## Применение передачи стиля к нашим изображениям"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "B6xIfs9ww0T6"
      },
      "source": [
        "### Запуск градиентного спуска\n",
        "Если вы не знакомы с градиентным спуском/обратным распространением или нуждаетесь в переподготовке, вам обязательно нужно перейти на этот [потрясающий ресурс](https://developers.google.com/machine-learning/crash-course/reduc-loss/gradient -descent).\n",
        "\n",
        "В этом случае мы юудем использовать оптимизатор [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam), чтобы минимизировать потери. Мы итеративно обновляем наш выходное изображение: мы не обновляем веса в сети, вместо этого мы обучаем входное изображение, чтобы минимизировать потери. Для того, что это сделать, мы должны знать, как рассчитывать потери и градиенты.\n",
        "\n",
        "\\* Обратите внимание, что c помощью L-BFGS, который не рекомендуется использовать в этом учебном пособии, поскольку основная мотивация этого учебного пособия заключалается в том, чтобы проиллюстрировать лучшие практики с мгновенным выполением, и с помощью Adam мы можем продемонстрировать функциональность autograd/gradient tape с помощью пользовательских циклов обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "NS3ohXq-w0T8"
      },
      "source": [
        "Мы определим небольшую вспомогательную функцию, которая будет загружать изображение содержания и изображение стиля, передавать их в сеть, которая затем будет выводить представления функций содержания и стиля нашей модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T13:06:34.660131Z",
          "start_time": "2019-07-16T13:06:34.647860Z"
        },
        "id": "O-lj5LxgtmnI"
      },
      "source": [
        "def get_feature_representations(model, content_path, style_path):\n",
        "    \"\"\"\n",
        "    Функция, которая рассчитывает признаки стиля и контента.\n",
        " \n",
        "    Эта функция будет просто предварительно подгружать и обрабатывать содержимое и стиль изображений. \n",
        "    Затем эти представления пройдут через сеть, чтобы получить промежуточные слои.\n",
        "  \n",
        "    Аргументы:\n",
        "      model: Используемая модель.\n",
        "      content_path: Путь к изображению содержимого.\n",
        "      style_path: Путь к изображению стиля.\n",
        "    \n",
        "    Возвращает:\n",
        "      Признаки стиля и контента.\n",
        "    \"\"\"\n",
        "    # Загрузка изображений\n",
        "    content_image = load_and_process_img(content_path)\n",
        "    style_image = load_and_process_img(style_path)\n",
        "\n",
        "    # Обработка признаков стиля и содержания\n",
        "    style_outputs = model(style_image)\n",
        "    content_outputs = model(content_image)\n",
        "\n",
        "    # Получение представлений признаков содержания стиля и содержания из модели\n",
        "    style_features = [style_layer[0]\n",
        "                      for style_layer in style_outputs[:num_style_layers]]\n",
        "    content_features = [content_layer[0]\n",
        "                        for content_layer in content_outputs[num_style_layers:]]\n",
        "    print(style_features)\n",
        "    return style_features, content_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "kPIVPhdFw0UH"
      },
      "source": [
        "### Вычисление функции потерь и градиентов\n",
        "Здесь мы используем [**tf.GradientTape**] (https://www.tensorflow.org/programmers _guide / eager # computing_ градиенты) для вычисления градиента. Это позволяет нам использовать преимущества автоматического дифференциирования, доступного благодаря отслеживанию операций для вычисления градиента. Он записывает операции во время прямого прохода и затем может вычислить градиент функции потерь относительно нашего входного изображения для обратного прохода."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T13:06:39.493762Z",
          "start_time": "2019-07-16T13:06:39.460085Z"
        },
        "id": "oVDhSo8iJunf"
      },
      "source": [
        "def compute_loss(model, loss_weights, init_image, gram_style_features, content_features):\n",
        "    \"\"\"Эта функция рассчитывает полную потерю.\n",
        "  \n",
        "    Аргументы:\n",
        "      model: Модель с нужными промежуточными слоями.\n",
        "      loss_weights: Вес каждого компонента для каждой функции потерь. \n",
        "        (вес для стиля, для содерджания и общий).\n",
        "      init_image: Первичное изображение. Это то изображение, которое в процессе оптимизации будет обновляться.\n",
        "      gram_style_features: Предварительные вычисления матрицы Грама соответствующих слоёв.\n",
        "      content_features: Предварительные вычисления нужных слоёв контента.\n",
        "      \n",
        "    Возвращает:\n",
        "      Общие потери, потери для стиля, содержания и вариационные потери\n",
        "    \"\"\"\n",
        "    style_weight, content_weight = loss_weights\n",
        "\n",
        "    # Прогон изображение через модель. Это даст представления содержания и стиля.\n",
        "    # Из-за использования мгновенного выполнения, эта модель вызывается как и любая другая функция.\n",
        "    model_outputs = model(init_image)\n",
        "\n",
        "    style_output_features = model_outputs[:num_style_layers]\n",
        "    content_output_features = model_outputs[num_style_layers:]\n",
        "\n",
        "    style_score = 0\n",
        "    content_score = 0\n",
        "\n",
        "    # Суммирует потерю стиля со всех слоёв\n",
        "    # Тут одинаково взвешиваются потери каждого слоя.\n",
        "    weight_per_style_layer = 1.0 / float(num_style_layers)\n",
        "    for target_style, comb_style in zip(gram_style_features, style_output_features):\n",
        "        style_score += weight_per_style_layer * \\\n",
        "            get_style_loss(comb_style[0], target_style)\n",
        "\n",
        "    # Суммирование потерь контента со всех слоёв\n",
        "    weight_per_content_layer = 1.0 / float(num_content_layers)\n",
        "    for target_content, comb_content in zip(content_features, content_output_features):\n",
        "        content_score += weight_per_content_layer * \\\n",
        "            get_content_loss(comb_content[0], target_content)\n",
        "\n",
        "    style_score *= style_weight\n",
        "    content_score *= content_weight\n",
        "\n",
        "    # Получение суммарной потери\n",
        "    loss = style_score + content_score\n",
        "    return loss, style_score, content_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5XTvbP6nJQa"
      },
      "source": [
        "В итоге расчёт градиента сводится к этому:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T13:06:40.751976Z",
          "start_time": "2019-07-16T13:06:40.746934Z"
        },
        "id": "fwzYeOqOUH9_"
      },
      "source": [
        "def compute_grads(cfg):\n",
        "    with tf.GradientTape() as tape:\n",
        "        all_loss = compute_loss(**cfg)\n",
        "    # Расчёт градиента изображения\n",
        "    total_loss = all_loss[0]\n",
        "    return tape.gradient(total_loss, cfg['init_image']), all_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9yKu2PLlBIE"
      },
      "source": [
        "### Оптимизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T13:06:42.037382Z",
          "start_time": "2019-07-16T13:06:41.861656Z"
        },
        "code_folding": [
          62
        ],
        "id": "pj_enNo6tACQ"
      },
      "source": [
        "import IPython.display\n",
        "\n",
        "def run_style_transfer(content_path, \n",
        "                       style_path,\n",
        "                       num_iterations=1000,\n",
        "                       content_weight=1e3, \n",
        "                       style_weight=1e-2): \n",
        "  # В этом случае не нужно обучать каждый слой модели. Поэтому параметр trainability нужно выставить в false.\n",
        "  model = get_model() \n",
        "  for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  # Получение представлений признаков стиля и контента (из промежуточных слоёв).\n",
        "  style_features, content_features = get_feature_representations(model, content_path, style_path)\n",
        "  gram_style_features = [gram_matrix(style_feature) for style_feature in style_features]\n",
        "  \n",
        "  # Загрузка исходного изображения\n",
        "  init_image = load_and_process_img(content_path)\n",
        "  init_image = tf.Variable(init_image, dtype=tf.float32)\n",
        "  # Создание оптимизатора\n",
        "  opt = tf.train.AdamOptimizer(learning_rate=5, beta1=0.99, epsilon=1e-1)\n",
        "\n",
        "  # Отображение промежуточных изображений\n",
        "  iter_count = 1\n",
        "  \n",
        "  # Сохранение лучшего результата\n",
        "  best_loss, best_img = float('inf'), None\n",
        "  \n",
        "  # Создание конфигурации\n",
        "  loss_weights = (style_weight, content_weight)\n",
        "  cfg = {\n",
        "      'model': model,\n",
        "      'loss_weights': loss_weights,\n",
        "      'init_image': init_image,\n",
        "      'gram_style_features': gram_style_features,\n",
        "      'content_features': content_features\n",
        "  }\n",
        "    \n",
        "  # Отображение\n",
        "  num_rows = 2\n",
        "  num_cols = 5\n",
        "  display_interval = num_iterations/(num_rows*num_cols)\n",
        "  start_time = time.time()\n",
        "  global_start = time.time()\n",
        "  \n",
        "  norm_means = np.array([103.939, 116.779, 123.68])\n",
        "  min_vals = -norm_means\n",
        "  max_vals = 255 - norm_means   \n",
        "  \n",
        "  imgs = []\n",
        "  for i in range(num_iterations):\n",
        "    grads, all_loss = compute_grads(cfg)\n",
        "    loss, style_score, content_score = all_loss\n",
        "    opt.apply_gradients([(grads, init_image)])\n",
        "    clipped = tf.clip_by_value(init_image, min_vals, max_vals)\n",
        "    init_image.assign(clipped)\n",
        "    end_time = time.time() \n",
        "    \n",
        "    if loss < best_loss:\n",
        "      # Обновление лучшей потери и изображения \n",
        "      best_loss = loss\n",
        "      best_img = deprocess_img(init_image.numpy())\n",
        "\n",
        "    if i % display_interval== 0:\n",
        "      start_time = time.time()\n",
        "      \n",
        "      # Используйте метод .numpy(), чтобы получить конкретный numpy-массив\n",
        "      plot_img = init_image.numpy()\n",
        "      plot_img = init_image.numpy()\n",
        "      plot_img = deprocess_img(plot_img)\n",
        "      imgs.append(plot_img)\n",
        "      IPython.display.clear_output(wait=True)\n",
        "      IPython.display.display_png(Image.fromarray(plot_img))\n",
        "      print('Iteration: {}'.format(i))        \n",
        "      print('Total loss: {:.4e}, ' \n",
        "            'style loss: {:.4e}, '\n",
        "            'content loss: {:.4e}, '\n",
        "            'time: {:.4f}s'.format(loss, style_score, content_score, time.time() - start_time))\n",
        "  print('Total time: {:.4f}s'.format(time.time() - global_start))\n",
        "  IPython.display.clear_output(wait=True)\n",
        "  plt.figure(figsize=(14,4))\n",
        "  for i,img in enumerate(imgs):\n",
        "      plt.subplot(num_rows,num_cols,i+1)\n",
        "      plt.imshow(img)\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      \n",
        "  return best_img, best_loss "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T13:09:24.316347Z",
          "start_time": "2019-07-16T13:07:53.819153Z"
        },
        "id": "vSVMx4burydi"
      },
      "source": [
        "best, best_loss = run_style_transfer(content_path,\n",
        "                                     style_path, num_iterations=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-16T13:06:56.212139Z",
          "start_time": "2019-07-16T13:06:56.197358Z"
        },
        "id": "dzJTObpsO3TZ"
      },
      "source": [
        "Image.fromarray(best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCXQ9vSnQbDy"
      },
      "source": [
        "Для того, чтобы загрузить изображение из Colab, расскоментируйте:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSH6OpyyQn7w"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.download('wave_turtle.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "UKkPKewaw0UV"
      },
      "source": [
        "## Визуализация результатов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqTQN1PjulV9"
      },
      "source": [
        "def show_results(best_img, content_path, style_path, show_large_final=True):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    content = load_img(content_path)\n",
        "    style = load_img(style_path)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    imshow(content, 'Изображение содержания')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    imshow(style, 'Изображение стиля')\n",
        "\n",
        "    if show_large_final:\n",
        "        plt.figure(figsize=(10, 10))\n",
        "\n",
        "        plt.imshow(best_img)\n",
        "        plt.title('Выходное изображение')\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6d6O50Yvs6a"
      },
      "source": [
        "show_results(best, content_path, style_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "2Srw_73Vw0UZ"
      },
      "source": [
        "## Попробуем на других изображениях\n",
        "Изображение Тюбингена\n",
        "\n",
        "Фото: Андреас Праефке [GFDL (http://www.gnu.org/copyleft/fdl.html) или CC BY 3.0 (https://creativecommons.org/licenses/by/3.0)], взято из Викисклада."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "-GW2rM4Pw0Ua"
      },
      "source": [
        "### Звездная ночь + Тюбинген"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES9dC6ZyJBD2"
      },
      "source": [
        "best_starry_night, best_loss = run_style_transfer('/tmp/nst/Tuebingen_Neckarfront.jpg',\n",
        "                                                  '/tmp/nst/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8w8WLkKvzXu"
      },
      "source": [
        "show_results(best_starry_night, '/tmp/nst/Tuebingen_Neckarfront.jpg',\n",
        "             '/tmp/nst/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la /tmp/nst"
      ],
      "metadata": {
        "id": "y1M0ZjnlY-o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Песик 1 + Ван Гог"
      ],
      "metadata": {
        "id": "8h9KSRUrLbRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_starry_night, best_loss = run_style_transfer(\"/tmp/nst/photo-2021-12-15-16-26-22.jpg\",\n",
        "                                                  \"/tmp/nst/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8LrSNDJtR0Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_results(best_starry_night, '/tmp/nst/photo-2021-12-15-16-26-22.jpg',\n",
        "             '/tmp/nst/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg')"
      ],
      "metadata": {
        "id": "CHGESVZ1SCbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Песик 2 + Кандинский"
      ],
      "metadata": {
        "id": "0d10vMOKLk6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_kandinsky_tubingen, best_loss = run_style_transfer('/tmp/nst/photo-2021-12-15-17-09-04.jpg', \n",
        "                                                  '/tmp/nst/Vassily_Kandinsky,_1913_-_Composition_7.jpg')"
      ],
      "metadata": {
        "id": "hRvfphfCcE07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_results(best_kandinsky_tubingen, \n",
        "             '/tmp/nst/photo-2021-12-15-17-09-04.jpg',\n",
        "             '/tmp/nst/Vassily_Kandinsky,_1913_-_Composition_7.jpg')"
      ],
      "metadata": {
        "id": "NzDUYwLKcFNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Волна"
      ],
      "metadata": {
        "id": "sNfyvsFnLrdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_poc_turtle, best_loss = run_style_transfer('/tmp/nst/1556707966_3.jpg', \n",
        "                                                  '/tmp/nst/The_Great_Wave_off_Kanagawa.jpg')"
      ],
      "metadata": {
        "id": "tHZSEh26iqR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_results(best_poc_turtle, \n",
        "             '/tmp/nst/1556707966_3.jpg',\n",
        "             '/tmp/nst/The_Great_Wave_off_Kanagawa.jpg')"
      ],
      "metadata": {
        "id": "AzMkpKmhi-Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "2OkPm4I9w0Uf"
      },
      "source": [
        "### Столпы Творения + Тюбинген"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ3u2U-gGmgP"
      },
      "source": [
        "best_poc_tubingen, best_loss = run_style_transfer('/tmp/nst/Tuebingen_Neckarfront.jpg',\n",
        "                                                  '/tmp/nst/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQUq3KxpGv2O"
      },
      "source": [
        "show_results(best_poc_tubingen, \n",
        "             '/tmp/nst/Tuebingen_Neckarfront.jpg',\n",
        "             '/tmp/nst/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "nDl33ml-w0Uj"
      },
      "source": [
        "### Кандинский Композиция 7 + Тюбинген"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt9mbQfl7exl"
      },
      "source": [
        "best_kandinsky_tubingen, best_loss = run_style_transfer('/tmp/nst/Tuebingen_Neckarfront.jpg', \n",
        "                                                  '/tmp/nst/Vassily_Kandinsky,_1913_-_Composition_7.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnz8HeXSXg6P"
      },
      "source": [
        "show_results(best_kandinsky_tubingen, \n",
        "             '/tmp/nst/Tuebingen_Neckarfront.jpg',\n",
        "             '/tmp/nst/Vassily_Kandinsky,_1913_-_Composition_7.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "cu52dKcEw0Uo"
      },
      "source": [
        "### Столпы Творения + Морская Черепаха"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl0DUot_bFST"
      },
      "source": [
        "best_poc_turtle, best_loss = run_style_transfer('/tmp/nst/Green_Sea_Turtle_grazing_seagrass.jpg', \n",
        "                                                  '/tmp/nst/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzJfE0I1bQn8"
      },
      "source": [
        "show_results(best_poc_turtle, \n",
        "             '/tmp/nst/Green_Sea_Turtle_grazing_seagrass.jpg',\n",
        "             '/tmp/nst/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_poc_turtle, best_loss = run_style_transfer('/tmp/nst/The_Great_Wave_off_Kanagawa.jpg', \n",
        "                                                  '/tmp/nst/1556707966_3.jpg')"
      ],
      "metadata": {
        "id": "ttGARLZOtewv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_results(best_poc_turtle, \n",
        "             '/tmp/nst/The_Great_Wave_off_Kanagawa.jpg',\n",
        "             '/tmp/nst/1556707966_3.jpg')"
      ],
      "metadata": {
        "id": "IkRJ2FsJtiZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "ru",
        "id": "QzzUOHyFw0Ut"
      },
      "source": [
        "## Ключевые результаты\n",
        "\n",
        "### Что мы сделали:\n",
        "\n",
        "*Мы создали несколько различных функций потерь и использовали метод обратного распространения для преобразования входного изображения, чтобы минимизировать потери*. Для этого нам пришлось загрузить **предварительно обученную модель** и использовать карты прихнаков для описания содержания и стиля изображений.\n",
        "    *Функции потерь в основном вычисляли расстояния различных представлений*. Мы реализовали это с помощью собственной модели и **моментального исполнения**.\n",
        "  *Мы создали собственную модель с помощью Functional API*. Моментальное исполнение позволяет нам динамически работать с тензорами, используя естественный поток управления Python.\n",
        "  *Мы напрямую управляли тензорами, что облегчило отладку и работу с тензорами.* Мы итеративно обновляли наше изображение, применяя правила обновления оптимизаторов с использованием **tf.gradient**. Оптимизатор минимизировал потери относительно входного изображения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-y02GWonqnD"
      },
      "source": [
        "\n",
        "**[Image of Tuebingen](https://commons.wikimedia.org/wiki/File:Tuebingen_Neckarfront.jpg)** \n",
        "Photo By: Andreas Praefcke [GFDL (http://www.gnu.org/copyleft/fdl.html) or CC BY 3.0  (https://creativecommons.org/licenses/by/3.0)], from Wikimedia Commons\n",
        "\n",
        "**[Image of Green Sea Turtle](https://commons.wikimedia.org/wiki/File:Green_Sea_Turtle_grazing_seagrass.jpg)**\n",
        "By P.Lindgren [CC BY-SA 3.0 (https://creativecommons.org/licenses/by-sa/3.0)], from Wikimedia Commons\n",
        "\n"
      ]
    }
  ]
}